- ğŸ‘‹ Hi, Iâ€™m @wrxjt
- ğŸ‘€ Iâ€™m interested in CV
- ğŸŒ± Iâ€™m currently learning Deep learning
- ğŸ’ï¸ Iâ€™m looking to collaborate on architecture CNN & VIT
- ğŸ“« How to reach me ...

Effiecient densenet
è¿‘åå¹´æ¥å·ç§¯ç¥ç»ç½‘ç»œå‘å±•å‡ºå„å¼å„æ ·çš„å˜ä½“ï¼Œä¸æ–­åœ°ä½¿ç½‘ç»œåŠ å®½åŠ æ·±ã€
ä½†æ˜¯å³ä¾¿æ¯ä¸ªç½‘ç»œæœ‰å„è‡ªåœ°ç‰¹ç‚¹ï¼Œåœ¨èåˆç½‘ç»œä¸Šå´åšçš„ä¸æ˜¯å¾ˆå¥½ã€‚
è¿™ç¯‡è®ºæ–‡ï¼Œæˆ‘ä»¬ä»¥densenetä¸ºåª’ä»‹ï¼Œæå‡ºä¸€ç§æ–°çš„æ¡†æ¶ï¼Œä½¿å¾—ç½‘ç»œèåˆå˜å¾—å¯è¡Œã€‚
å…·ä½“æ¥è¯´ï¼Œdensenetçš„ç¬¬lå±‚æ¥å—å‰l-1å±‚çš„ç‰¹å¾å›¾ï¼Œä¸”æ¯ä¸ªç‰¹å¾å›¾çš„é€šé“æ•°éƒ½ä¸ºkã€‚
æˆ‘ä»¬è®¤ä¸ºå¯¹äºç¬¬lå±‚æ¥è¯´ï¼Œç¬¬l-1å±‚çš„ç‰¹å¾å›¾æ˜¯æœ€é‡è¦çš„ä¿¡æ¯æµï¼Œæ‰€ä»¥å®ƒçš„é€šé“æ•°åº”è¯¥
è¿œè¿œå¤§äºkï¼Œä»è€Œæˆ‘ä»¬å¼•å‡ºä¸€æ¡æ”¯è·¯ç½‘ç»œï¼Œä½¿å¾—ç¬¬l-1å±‚çš„ç‰¹å¾å›¾è¢«å……åˆ†å­¦ä¹ ã€‚è€Œè¿™ä¸ª
æ”¯è·¯ç½‘ç»œå¯ä»¥ç”¨ä»»æ„ç½‘ç»œå¡«å……ï¼Œä¸ºäº†ä½¿å¾—è¿™ä¸ªdensenetå˜ä½“å…·æœ‰å¤šæ ·æ€§ï¼Œæˆ‘ä»¬è®¾è®¡äº†
ä¸€ä¸ªç½‘ç»œå—èåˆäº†å„ä¸ªç½‘ç»œçš„ç‰¹æ€§ã€‚å¦ä¸€æ–¹é¢ï¼Œç”±äºè¿™æ¡æ”¯è·¯ç½‘ç»œçš„å¯æ›¿ä»£æ€§å’Œå¯å¯¹é½æ€§ï¼Œ
æˆ‘ä»¬å¯ä»¥å°†ä¸»æµåŸºå‡†ç½‘ç»œå¯¹æ ‡æ”¾å…¥ï¼Œå¹¶åˆ©ç”¨ä¸Šè¿°è®¾è®¡å—å……å½“densenetå—èå…¥ã€‚è¿™ç§è®¾è®¡ç›¸
å½“äºå¯¹ä»»æ„çš„åŸºå‡†ç½‘ç»œæ·»åŠ densenetç½‘ç»œçš„æ€§èƒ½ã€‚è€Œå¦‚æœè¿™ä¸ªå—æ˜¯è‡ªå®šä¹‰å—ï¼Œåˆ™å¯ä»¥èåˆ
å¤šä¸ªç½‘ç»œçš„ç‰¹ç‚¹ï¼Œä»è€Œè¾¾åˆ°äº†ç½‘ç»œèåˆã€‚æˆ‘ä»¬åˆ©ç”¨æ”¹è¿›åçš„ç½‘ç»œåœ¨cifar10,cifar100,svhnæ•°
æ®é›†ä¸Šè¿›è¡Œæµ‹è¯•ï¼Œå–å¾—äº†æƒŠäººçš„è¿›å±•ã€‚
cnn has dominated the CV space since alexnet burst onto the scene. In recent years, there have been many improved networks, but with the increasing width and depth of the network, bottlenecks gradually appear, making the progress of traditional CNN in the past two years begin to develop towards the direction of NAS network search. Transformer model began to enter the field of computer vision. vit,swintransformer and other models proved that without the use of convolutional neural network, excellent results could be achieved and they tried to unify the country. Multimodal learning moco,clip, mae also shine. However, since the transformer model needs to learn from an unusually large data set, it is difficult to prove whether the effect of the above model is due to the model itself or the large amount of ancient data. The convnet shows that the traditional convolutional neural network may not be worse than vit, and in the past two years, many networks have fused vit with cnn, proving that convolutional neural network is still indelible in computer vision.
In this paper, we try to integrate the excellent cnn network with densenet in recent years, so that the characteristics of most networks can be brought into play with one network, so as to achieve more efficient and stable performance. We propose two improvements based on densenet.
The first kind of network is densenet as the main network and integrates features of other networks. The reason we do this is that densenet accepts the same number of channels in the feature map of the first l-1 layer, which is obviously not the optimal solution. Because for layer l it mainly learns the features of layer l minus 1. To this end, we increase the number of channels of the l-1 layer feature map, and these additional feature maps can be learned by using another network. We do this to make the additional feature map can be learned by other high-performance networks, so as to achieve the characteristics of other networks and densenet combination. So, we designed a network that combines the features of googlenet and resnext. In addition, we believe that for layer l, the closer the layer is to it (l-2, L-3...). The feature maps of are fully learned, so to prevent overfitting, we cut off the reuse of feature maps within two layers apart. This not only indirectly reduces the parameters, but also prevents overfitting.
The second improved network is to put the baseline network into the red line as the main network as shown in the figure, and then put the corresponding blocks into the densenet network. In this way, the baseline network can have the characteristics of densenet and the corresponding blocks without changing the original characteristics, and realize the network fusion. Intuitively, if the features in the two networks are fundamentally different, the results are at least better than they would have been. This network also indirectly verifies that there are real differences in the characteristics of the emerging networks,
